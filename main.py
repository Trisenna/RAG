"""
RAGç³»ç»Ÿä¸»å…¥å£æ–‡ä»¶
æ”¯æŒå‘½ä»¤è¡Œæ“ä½œå’ŒAPIæœåŠ¡å¯åŠ¨
"""

import os
import sys
import json
import asyncio
import argparse
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from core.config.settings import settings
from core.config.llm_config import llm_config_manager
from services.indexing import IndexingService
from services.search import SearchService
from services.rag import RAGService
from services.contextual_rag import ContextualRAGService

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=getattr(logging, settings.LOG_LEVEL),
    format=settings.LOG_FORMAT
)
logger = logging.getLogger(__name__)


def setup_environment():
    """è®¾ç½®ç¯å¢ƒå˜é‡å’Œé…ç½®"""
    # è®¾ç½® Hugging Face é•œåƒå’Œç¼“å­˜è·¯å¾„
    os.environ.setdefault('HF_ENDPOINT', 'https://hf-mirror.com')
    os.environ.setdefault('TRANSFORMERS_CACHE', '/tmp/transformers_cache')

    # éªŒè¯é…ç½®
    if not settings.validate_config():
        logger.error("é…ç½®éªŒè¯å¤±è´¥")
        sys.exit(1)

    # éªŒè¯LLMé…ç½®
    if not llm_config_manager.validate_all_configs():
        logger.error("LLMé…ç½®éªŒè¯å¤±è´¥")
        sys.exit(1)

    logger.info("ç¯å¢ƒé…ç½®å®Œæˆ")


def create_argument_parser():
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="é«˜çº§RAGç³»ç»Ÿå‘½ä»¤è¡Œå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  %(prog)s index --path /path/to/documents    # ç´¢å¼•æŒ‡å®šç›®å½•
  %(prog)s query --text "ä½ çš„é—®é¢˜"            # æ‰§è¡Œæœç´¢æŸ¥è¯¢
  %(prog)s rag --query "æ™ºèƒ½é—®ç­”"             # æ‰§è¡ŒRAGé—®ç­”
  %(prog)s serve --host 0.0.0.0 --port 8000  # å¯åŠ¨APIæœåŠ¡
        """
    )

    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # ç´¢å¼•å‘½ä»¤
    index_parser = subparsers.add_parser("index", help="ç´¢å¼•æ–‡æ¡£")
    index_parser.add_argument("--path", "-p", help="è¦ç´¢å¼•çš„æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„")
    index_parser.add_argument("--delete", "-d", action="store_true", help="åˆ é™¤ç°æœ‰ç´¢å¼•åé‡æ–°ç´¢å¼•")
    index_parser.add_argument("--recreate", action="store_true", help="é‡æ–°åˆ›å»ºç´¢å¼•ç»“æ„")
    index_parser.add_argument("--concurrent", "-c", type=int, default=3, help="å¹¶å‘æ–‡ä»¶æ•°é‡")

    # æœç´¢å‘½ä»¤
    search_parser = subparsers.add_parser("search", help="æœç´¢æ–‡æ¡£")
    search_parser.add_argument("--text", "-t", required=True, help="æœç´¢æ–‡æœ¬")
    search_parser.add_argument("--top-k", "-k", type=int, default=4, help="è¿”å›çš„æœ€å¤§æ–‡æ¡£æ•°é‡")
    search_parser.add_argument("--type", choices=["hybrid", "semantic", "keyword"],
                              default="hybrid", help="æœç´¢ç±»å‹")

    # RAGæŸ¥è¯¢å‘½ä»¤
    rag_parser = subparsers.add_parser("rag", help="RAGé—®ç­”")
    rag_parser.add_argument("--query", "-q", required=True, help="é—®ç­”æŸ¥è¯¢")
    rag_parser.add_argument("--top-k", "-k", type=int, default=5, help="æ£€ç´¢çš„æœ€å¤§æ–‡æ¡£æ•°é‡")
    rag_parser.add_argument("--contextual", action="store_true", help="ä½¿ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥RAG")
    rag_parser.add_argument("--session-id", help="ä¼šè¯IDï¼ˆç”¨äºä¸Šä¸‹æ–‡æ„ŸçŸ¥RAGï¼‰")
    rag_parser.add_argument("--no-rewrite", action="store_true", help="ç¦ç”¨æŸ¥è¯¢é‡å†™")
    rag_parser.add_argument("--no-decompose", action="store_true", help="ç¦ç”¨æŸ¥è¯¢åˆ†è§£")
    rag_parser.add_argument("--no-rerank", action="store_true", help="ç¦ç”¨é‡æ’åº")
    rag_parser.add_argument("--no-citation", action="store_true", help="ç¦ç”¨å¼•ç”¨")

    # æœåŠ¡å¯åŠ¨å‘½ä»¤
    serve_parser = subparsers.add_parser("serve", help="å¯åŠ¨APIæœåŠ¡")
    serve_parser.add_argument("--host", default=settings.API_HOST, help="ä¸»æœºåœ°å€")
    serve_parser.add_argument("--port", "-p", type=int, default=settings.API_PORT, help="ç«¯å£å·")
    serve_parser.add_argument("--reload", action="store_true", help="å¯ç”¨è‡ªåŠ¨é‡è½½")
    serve_parser.add_argument("--workers", type=int, default=1, help="å·¥ä½œè¿›ç¨‹æ•°é‡")

    # çŠ¶æ€å‘½ä»¤
    status_parser = subparsers.add_parser("status", help="æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€")
    status_parser.add_argument("--detail", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯")

    # é…ç½®å‘½ä»¤
    config_parser = subparsers.add_parser("config", help="é…ç½®ç®¡ç†")
    config_parser.add_argument("--show", action="store_true", help="æ˜¾ç¤ºå½“å‰é…ç½®")
    config_parser.add_argument("--test", action="store_true", help="æµ‹è¯•é…ç½®")

    return parser


async def handle_index_command(args):
    """å¤„ç†ç´¢å¼•å‘½ä»¤"""
    try:
        indexing_service = IndexingService(max_concurrent_files=args.concurrent)

        if args.recreate:
            logger.info("é‡æ–°åˆ›å»ºç´¢å¼•ç»“æ„...")
            result = indexing_service.recreate_index()
            print(json.dumps(result, ensure_ascii=False, indent=2))

        if args.delete:
            logger.info("åˆ é™¤ç°æœ‰ç´¢å¼•...")
            indexing_service.delete_all_indexes()

        path = args.path or settings.DOCUMENTS_DIR

        if os.path.isfile(path):
            logger.info(f"ç´¢å¼•æ–‡ä»¶: {path}")
            result = await indexing_service.index_file(path)
        else:
            logger.info(f"ç´¢å¼•ç›®å½•: {path}")
            result = await indexing_service.index_directory(path)

        print(json.dumps(result, ensure_ascii=False, indent=2))

    except Exception as e:
        logger.error(f"ç´¢å¼•æ“ä½œå¤±è´¥: {str(e)}")
        sys.exit(1)


async def handle_search_command(args):
    """å¤„ç†æœç´¢å‘½ä»¤"""
    try:
        search_service = SearchService()

        if args.type == "semantic":
            result = search_service.semantic_search(args.text, top_k=args.top_k)
        elif args.type == "keyword":
            result = search_service.keyword_search(args.text, top_k=args.top_k)
        else:  # hybrid
            result = search_service.search_documents(args.text, top_k=args.top_k)

        print(json.dumps(result, ensure_ascii=False, indent=2))

    except Exception as e:
        logger.error(f"æœç´¢æ“ä½œå¤±è´¥: {str(e)}")
        sys.exit(1)


async def handle_rag_command(args):
    """å¤„ç†RAGé—®ç­”å‘½ä»¤"""
    try:
        # æ„å»ºRAGé…ç½®
        rag_config = {
            "use_query_rewriting": not args.no_rewrite,
            "use_query_decomposition": not args.no_decompose,
            "use_reranking": not args.no_rerank,
            "use_citation": not args.no_citation
        }

        if args.contextual:
            # ä½¿ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥RAG
            rag_service = ContextualRAGService(**rag_config)
            result = await rag_service.query_async(
                args.query,
                session_id=args.session_id,
                top_k=args.top_k
            )
        else:
            # ä½¿ç”¨åŸºç¡€RAG
            rag_service = RAGService(**rag_config)
            result = await rag_service.query_async(args.query, top_k=args.top_k)

        # æ ¼å¼åŒ–è¾“å‡º
        print("=" * 60)
        print(f"æŸ¥è¯¢: {args.query}")
        print("=" * 60)
        print(f"å›ç­”: {result.get('answer', 'N/A')}")

        if result.get("sources"):
            print("\næ¥æº:")
            for i, source in enumerate(result["sources"], 1):
                filename = source.get("filename", "æœªçŸ¥æ–‡ä»¶")
                score = source.get("score", 0)
                print(f"  [{i}] {filename} (ç›¸å…³æ€§: {score:.3f})")

        if args.contextual and "session_id" in result:
            print(f"\nä¼šè¯ID: {result['session_id']}")

        print(f"\nå¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f}ç§’")

        # ä¿å­˜å®Œæ•´ç»“æœåˆ°æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        if os.environ.get("RAG_SAVE_RESULTS"):
            with open("rag_result.json", "w", encoding="utf-8") as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print("å®Œæ•´ç»“æœå·²ä¿å­˜åˆ° rag_result.json")

    except Exception as e:
        logger.error(f"RAGé—®ç­”å¤±è´¥: {str(e)}")
        sys.exit(1)


def handle_serve_command(args):
    """å¤„ç†æœåŠ¡å¯åŠ¨å‘½ä»¤"""
    try:
        import uvicorn
        from api.app import app

        logger.info(f"å¯åŠ¨RAG APIæœåŠ¡å™¨: {args.host}:{args.port}")

        uvicorn.run(
            "api.app:app",
            host=args.host,
            port=args.port,
            reload=args.reload,
            workers=args.workers,
            log_level=settings.LOG_LEVEL.lower()
        )

    except Exception as e:
        logger.error(f"å¯åŠ¨APIæœåŠ¡å¤±è´¥: {str(e)}")
        sys.exit(1)


async def handle_status_command(args):
    """å¤„ç†çŠ¶æ€æŸ¥çœ‹å‘½ä»¤"""
    try:
        status_info = {}

        # åŸºæœ¬ä¿¡æ¯
        status_info["system"] = {
            "python_version": sys.version,
            "project_root": str(project_root),
            "documents_directory": settings.DOCUMENTS_DIR,
            "log_level": settings.LOG_LEVEL
        }

        # ç´¢å¼•çŠ¶æ€
        try:
            indexing_service = IndexingService()
            status_info["indexing"] = indexing_service.get_index_statistics()
        except Exception as e:
            status_info["indexing"] = {"error": str(e)}

        # æœç´¢çŠ¶æ€
        try:
            search_service = SearchService()
            status_info["search"] = search_service.test_connection()
        except Exception as e:
            status_info["search"] = {"error": str(e)}

        if args.detail:
            # RAGæœåŠ¡çŠ¶æ€
            try:
                rag_service = RAGService()
                status_info["rag"] = rag_service.get_service_info()
            except Exception as e:
                status_info["rag"] = {"error": str(e)}

            # ä¸Šä¸‹æ–‡æ„ŸçŸ¥RAGæœåŠ¡çŠ¶æ€
            try:
                contextual_rag = ContextualRAGService()
                status_info["contextual_rag"] = contextual_rag.get_service_info()
            except Exception as e:
                status_info["contextual_rag"] = {"error": str(e)}

        print(json.dumps(status_info, ensure_ascii=False, indent=2))

    except Exception as e:
        logger.error(f"è·å–çŠ¶æ€ä¿¡æ¯å¤±è´¥: {str(e)}")
        sys.exit(1)


def handle_config_command(args):
    """å¤„ç†é…ç½®ç®¡ç†å‘½ä»¤"""
    try:
        if args.show:
            config_info = {
                "settings": {
                    "API_HOST": settings.API_HOST,
                    "API_PORT": settings.API_PORT,
                    "DOCUMENTS_DIR": settings.DOCUMENTS_DIR,
                    "ELASTICSEARCH_URL": settings.ELASTICSEARCH_URL,
                    "ELASTICSEARCH_INDEX_NAME": settings.ELASTICSEARCH_INDEX_NAME,
                    "CHUNK_SIZE": settings.CHUNK_SIZE,
                    "CHUNK_OVERLAP": settings.CHUNK_OVERLAP,
                    "LOG_LEVEL": settings.LOG_LEVEL
                },
                "llm_config": {
                    "openai_model": llm_config_manager.openai_config.model,
                    "openai_api_base": llm_config_manager.openai_config.api_base,
                    "temperature": llm_config_manager.openai_config.temperature,
                    "max_tokens": llm_config_manager.openai_config.max_tokens
                }
            }
            print(json.dumps(config_info, ensure_ascii=False, indent=2))

        if args.test:
            print("æµ‹è¯•é…ç½®...")

            # æµ‹è¯•åŸºç¡€é…ç½®
            config_valid = settings.validate_config()
            print(f"åŸºç¡€é…ç½®: {'âœ“' if config_valid else 'âœ—'}")

            # æµ‹è¯•LLMé…ç½®
            llm_valid = llm_config_manager.validate_all_configs()
            print(f"LLMé…ç½®: {'âœ“' if llm_valid else 'âœ—'}")

            # æµ‹è¯•ç›®å½•
            docs_dir_exists = os.path.exists(settings.DOCUMENTS_DIR)
            print(f"æ–‡æ¡£ç›®å½•: {'âœ“' if docs_dir_exists else 'âœ—'} ({settings.DOCUMENTS_DIR})")

            overall_status = config_valid and llm_valid and docs_dir_exists
            print(f"\næ€»ä½“çŠ¶æ€: {'âœ“ é…ç½®æ­£å¸¸' if overall_status else 'âœ— é…ç½®å¼‚å¸¸'}")

            if not overall_status:
                sys.exit(1)

    except Exception as e:
        logger.error(f"é…ç½®æ“ä½œå¤±è´¥: {str(e)}")
        sys.exit(1)

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®ç¯å¢ƒ
    setup_environment()

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = create_argument_parser()
    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    # æ ¹æ®å‘½ä»¤æ‰§è¡Œç›¸åº”æ“ä½œ
    try:
        if args.command == "index":
            asyncio.run(handle_index_command(args))
        elif args.command == "search":
            asyncio.run(handle_search_command(args))
        elif args.command == "rag":
            asyncio.run(handle_rag_command(args))
        elif args.command == "serve":
            handle_serve_command(args)  # ğŸš« ä¸ç”¨ asyncio.run
        elif args.command == "status":
            asyncio.run(handle_status_command(args))
        elif args.command == "config":
            handle_config_command(args)
        else:
            parser.print_help()

    except KeyboardInterrupt:
        logger.info("æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        logger.error(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()
